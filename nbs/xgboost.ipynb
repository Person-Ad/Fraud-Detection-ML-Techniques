{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af231b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ahmed Osama\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from evaluation import evaluate_model\n",
    "from preprocessing import *\n",
    "from sklearn import preprocessing\n",
    "import xgboost as xgb\n",
    "import gc\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "sns.set_theme(\n",
    "    style=\"whitegrid\",       # Background style (\"whitegrid\", \"darkgrid\", etc.)\n",
    "    palette=\"deep\",          # Default color palette (\"deep\", \"muted\", \"bright\", etc.)\n",
    "    font=\"sans-serif\",       # Font family\n",
    "    font_scale=1.1,          # Scale font size slightly\n",
    "    rc={\"figure.figsize\": (8, 5)}  # Default figure size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69df4d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = Path(\"../datasets\")\n",
    "\n",
    "train_identity = pd.read_csv(dataset_path / \"train_identity.csv\")\n",
    "train_tx = pd.read_csv(dataset_path / \"train_transaction.csv\")\n",
    "\n",
    "# test_identity = pd.read_csv(dataset_path / \"test_identity.csv\")\n",
    "# test_tx = pd.read_csv(dataset_path / \"test_transaction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae9a52bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_cols = pd.merge(train_tx, train_identity, on='TransactionID', how='left')\n",
    "# test_all_cols = pd.merge(train_tx, train_identity, on='TransactionID', how='left')\n",
    "\n",
    "X =  train_all_cols.drop(columns=['isFraud'])\n",
    "y = train_all_cols['isFraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc00eb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_shape: (590540, 433)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_shape: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30f5c623",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dbc916a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_val, X_test = run_feature_engineering(X_train, X_val, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c283ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping columns: ['V118', 'V123', 'id_22', 'V114', 'V300', 'V119', 'id_25', 'id_07', 'V109', 'V117', 'TransactionDT', 'V120', 'V305', 'id_21', 'V122', 'id_27', 'id_26', 'id_08', 'V311', 'V108', 'C3', 'V110', 'V116', 'V112', 'V107', 'id_24', 'id_23', 'V111', 'V121', 'V115', 'V286', 'V113', 'V301']\n",
      "Train shape: (472432, 400)\n",
      "Val shape: (118108, 400)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test  = preprocess_datasets(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d3eb7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_val, X_test = run_feature_engineering(X_train, X_val, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb126c7",
   "metadata": {},
   "source": [
    "## XGBoost without Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8708370d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ahmed Osama\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [17:50:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "scale_pos_weight = sum(y_train == 0) / sum(y_train == 1)\n",
    "\n",
    "model = xgb.XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=17,\n",
    "    learning_rate=0.03,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    tree_method='hist',\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='auc',\n",
    "    missing=-999,\n",
    "    random_state=42,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641e3796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score:  0.810010764262648\n",
      "Recall:  0.7282845390757319\n",
      "Precision:  0.9123976962715975\n",
      "Accuracy:  0.9880448403156433\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, recall_score, precision_score,accuracy_score\n",
    "# y_pred = model.predict(X_test)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"F1 Score: \", f1_score(y_test, y_pred))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred))\n",
    "print(\"Precision: \", precision_score(y_test, y_pred))\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80652b67",
   "metadata": {},
   "source": [
    "## XGBoost with K Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78253581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping columns: ['V122', 'V111', 'TransactionDT', 'id_27', 'V108', 'id_07', 'V286', 'V305', 'V116', 'V115', 'id_23', 'V113', 'V109', 'V110', 'id_08', 'id_26', 'id_24', 'V120', 'id_25', 'V114', 'V119', 'V123', 'V300', 'V118', 'V301', 'V121', 'id_21', 'V112', 'V117', 'V311', 'V107', 'id_22', 'C3']\n",
      "Train shape: (472432, 400)\n",
      "Val shape: (118108, 400)\n",
      "\n",
      "ðŸš€ Fold 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ahmed Osama\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [17:27:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Recall: 0.6878025169409487\n",
      "Fold 1 - Precision: 0.9033693579148124\n",
      "Fold 1 - F1 Score: 0.7809837867546029\n",
      "\n",
      "ðŸš€ Fold 2/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ahmed Osama\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [17:32:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 - Recall: 0.6749757986447241\n",
      "Fold 2 - Precision: 0.9069918699186992\n",
      "Fold 2 - F1 Score: 0.7739697516303594\n",
      "\n",
      "ðŸš€ Fold 3/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ahmed Osama\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [17:36:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 - Recall: 0.6866682796999758\n",
      "Fold 3 - Precision: 0.8989547038327527\n",
      "Fold 3 - F1 Score: 0.7786008230452675\n",
      "\n",
      "ðŸš€ Fold 4/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ahmed Osama\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [17:41:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 - Recall: 0.6825550447616743\n",
      "Fold 4 - Precision: 0.9050368944497915\n",
      "Fold 4 - F1 Score: 0.7782068965517241\n",
      "\n",
      "ðŸ“Š Final OOF Evaluation:\n",
      "OOF Recall: 0.6830006049606776\n",
      "OOF Precision: 0.9035614245698279\n",
      "OOF F1 Score: 0.7779500430663221\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from cross_validation import cross_validate_model\n",
    "\n",
    "model = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=17,\n",
    "    learning_rate=0.03,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    tree_method='hist',\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='auc',\n",
    "    random_state=42,\n",
    "    scale_pos_weight=sum(y_train == 0) / sum(y_train == 1)\n",
    ")\n",
    "\n",
    "cross_validate_model(model, X_train, y_train, X_test, y_test, epochs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2bd0cb",
   "metadata": {},
   "source": [
    "## Searching best combination of Feature Engineering Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810c7ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš§ Starting feature engineering pipeline...\n",
      "\n",
      "âœ… Low-information columns dropped\n",
      "âœ… Data cleaned\n",
      "âœ… Categorical columns encoded\n",
      "âœ… Missing values filled\n",
      "âœ… Unused columns dropped\n",
      "âœ… Numeric features standardized\n",
      "ðŸŽ¯ Final shape: (377945, 397)\n",
      "ðŸš§ Starting feature engineering pipeline...\n",
      "\n",
      "âœ… Low-information columns dropped\n",
      "âœ… Data cleaned\n",
      "âœ… Categorical columns encoded\n",
      "âœ… Missing values filled\n",
      "âœ… Unused columns dropped\n",
      "âœ… Numeric features standardized\n",
      "ðŸŽ¯ Final shape: (94487, 397)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ahmed Osama\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [16:09:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     14\u001b[39m X_train_processed = run_feature_engineering_single_df(X_train.copy(), config)\n\u001b[32m     15\u001b[39m X_val_processed = run_feature_engineering_single_df(X_val.copy(), config)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m f1 = \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_processed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val_processed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mâœ… F1-score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\code\\University\\Machine-Learning-Project\\nbs\\preprocessing.py:128\u001b[39m, in \u001b[36mevaluate_model\u001b[39m\u001b[34m(X_train, X_val, model, y_train, y_val)\u001b[39m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mevaluate_model\u001b[39m(X_train: pd.DataFrame, X_val: pd.DataFrame, model, y_train: pd.Series, y_val: pd.Series) -> \u001b[38;5;28mfloat\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    129\u001b[39m     y_pred = model.predict(X_val)\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m f1_score(y_val, y_pred)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ahmed Osama\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ahmed Osama\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\sklearn.py:1682\u001b[39m, in \u001b[36mXGBClassifier.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[39m\n\u001b[32m   1660\u001b[39m model, metric, params, feature_weights = \u001b[38;5;28mself\u001b[39m._configure_fit(\n\u001b[32m   1661\u001b[39m     xgb_model, params, feature_weights\n\u001b[32m   1662\u001b[39m )\n\u001b[32m   1663\u001b[39m train_dmatrix, evals = _wrap_evaluation_matrices(\n\u001b[32m   1664\u001b[39m     missing=\u001b[38;5;28mself\u001b[39m.missing,\n\u001b[32m   1665\u001b[39m     X=X,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1679\u001b[39m     feature_types=\u001b[38;5;28mself\u001b[39m.feature_types,\n\u001b[32m   1680\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m \u001b[38;5;28mself\u001b[39m._Booster = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1683\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1684\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1685\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1686\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1687\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1688\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1696\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.objective):\n\u001b[32m   1697\u001b[39m     \u001b[38;5;28mself\u001b[39m.objective = params[\u001b[33m\"\u001b[39m\u001b[33mobjective\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ahmed Osama\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ahmed Osama\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.before_iteration(bst, i, dtrain, evals):\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m \u001b[43mbst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.after_iteration(bst, i, dtrain, evals):\n\u001b[32m    185\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ahmed Osama\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:2247\u001b[39m, in \u001b[36mBooster.update\u001b[39m\u001b[34m(self, dtrain, iteration, fobj)\u001b[39m\n\u001b[32m   2243\u001b[39m \u001b[38;5;28mself\u001b[39m._assign_dmatrix_features(dtrain)\n\u001b[32m   2245\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2246\u001b[39m     _check_call(\n\u001b[32m-> \u001b[39m\u001b[32m2247\u001b[39m         \u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2248\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\n\u001b[32m   2249\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2250\u001b[39m     )\n\u001b[32m   2251\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2252\u001b[39m     pred = \u001b[38;5;28mself\u001b[39m.predict(dtrain, output_margin=\u001b[38;5;28;01mTrue\u001b[39;00m, training=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'drop_low_information_columns': True,\n",
    "    'drop_transaction_dt': True,\n",
    "    'encode_categorical_columns': True,\n",
    "    'fill_missing_values': True,\n",
    "    'create_transaction_amount_ratios': False,\n",
    "    'group_rare_categories': False,\n",
    "    'create_time_features': False,\n",
    "    'drop_unused_columns': True,\n",
    "    'log_transform_transaction_amt': False\n",
    "}\n",
    "\n",
    "\n",
    "X_train_processed = run_feature_engineering_single_df(X_train.copy(), config)\n",
    "X_val_processed = run_feature_engineering_single_df(X_val.copy(), config)\n",
    "\n",
    "f1 = evaluate_model(X_train_processed, X_val_processed, model, y_train, y_val)\n",
    "print(f\"âœ… F1-score: {f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
