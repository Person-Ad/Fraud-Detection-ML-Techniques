{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af231b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ahmed Osama\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import lightgbm as lgb\n",
    "\n",
    "from evaluate import evaluate\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "sns.set_theme(\n",
    "    style=\"whitegrid\",       # Background style (\"whitegrid\", \"darkgrid\", etc.)\n",
    "    palette=\"deep\",          # Default color palette (\"deep\", \"muted\", \"bright\", etc.)\n",
    "    font=\"sans-serif\",       # Font family\n",
    "    font_scale=1.1,          # Scale font size slightly\n",
    "    rc={\"figure.figsize\": (8, 5)}  # Default figure size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69df4d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = Path(\"../datasets\")\n",
    "\n",
    "train_identity = pd.read_csv(dataset_path / \"train_identity.csv\")\n",
    "train_tx = pd.read_csv(dataset_path / \"train_transaction.csv\")\n",
    "\n",
    "test_identity = pd.read_csv(dataset_path / \"test_identity.csv\")\n",
    "test_tx = pd.read_csv(dataset_path / \"test_transaction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae9a52bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_cols = pd.merge(train_tx, train_identity, on='TransactionID', how='left')\n",
    "# test = pd.merge(train_tx, train_identity, on='TransactionID', how='left')\n",
    "\n",
    "X =  train_all_cols.drop(columns=['isFraud'])\n",
    "y = train_all_cols['isFraud']\n",
    "X = X.fillna(-999) #* for lightgbm to handl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc00eb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_shape: (590540, 433)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_shape: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d975e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "num_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f42fcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[cat_cols] = X[cat_cols].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30f5c623",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.2, stratify=y_temp, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c283ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def encode_categorical_columns(X_train, X_val, X_test):\n",
    "    cat_cols = X_train.select_dtypes(include=['object']).columns\n",
    "    for col in cat_cols:\n",
    "        le = LabelEncoder()\n",
    "        combined = pd.concat([X_train[col], X_val[col], X_test[col]], axis=0).astype(str)\n",
    "        le.fit(combined)\n",
    "        X_train[col] = le.transform(X_train[col].astype(str))\n",
    "        X_val[col] = le.transform(X_val[col].astype(str))\n",
    "        X_test[col] = le.transform(X_test[col].astype(str))\n",
    "    return X_train, X_val, X_test\n",
    "\n",
    "def group_rare_categories(X_train, X_val, X_test, features, threshold=500):\n",
    "    for col in features:\n",
    "        freq = X_train[col].value_counts()\n",
    "        rare = freq[freq < threshold].index\n",
    "        for X in [X_train, X_val, X_test]:\n",
    "            if col in X.columns:\n",
    "                X[col] = X[col].replace(rare, 'Rare')\n",
    "    return X_train, X_val, X_test\n",
    "\n",
    "def create_transaction_amount_ratios(X_train, X_val, X_test, group_cols):\n",
    "    for col in group_cols:\n",
    "        # Train ratios\n",
    "        train_means = X_train.groupby(col, observed=False)['TransactionAmt'].transform('mean')\n",
    "        train_stds = X_train.groupby(col, observed=False)['TransactionAmt'].transform('std')\n",
    "        X_train[f'TransactionAmt_to_mean_{col}'] = X_train['TransactionAmt'] / train_means\n",
    "        X_train[f'TransactionAmt_to_std_{col}'] = X_train['TransactionAmt'] / train_stds\n",
    "\n",
    "        # Use train stats for val and test\n",
    "        means = X_train.groupby(col, observed=False)['TransactionAmt'].mean().to_dict()\n",
    "        stds = X_train.groupby(col, observed=False)['TransactionAmt'].std().to_dict()\n",
    "\n",
    "        for X in [X_val, X_test]:\n",
    "            mapped_means = X[col].map(means).astype(float)\n",
    "            mapped_stds = X[col].map(stds).astype(float)\n",
    "            X[f'TransactionAmt_to_mean_{col}'] = X['TransactionAmt'] / mapped_means\n",
    "            X[f'TransactionAmt_to_std_{col}'] = X['TransactionAmt'] / mapped_stds\n",
    "    return X_train, X_val, X_test\n",
    "\n",
    "def fill_missing_values(X, reference):\n",
    "    numeric_cols = reference.select_dtypes(include=[np.number]).columns\n",
    "    numeric_cols_existing = [col for col in numeric_cols if col in X.columns]\n",
    "    X[numeric_cols_existing] = X[numeric_cols_existing].fillna(-1)\n",
    "\n",
    "    cat_cols = reference.select_dtypes(include=['object']).columns\n",
    "    cat_cols_existing = [col for col in cat_cols if col in X.columns]\n",
    "    X[cat_cols_existing] = X[cat_cols_existing].fillna('missing')\n",
    "    return X\n",
    "\n",
    "def create_time_features(X):\n",
    "    X['TransactionDT_days'] = X['TransactionDT'] / (24 * 60 * 60)\n",
    "    X['Transaction_hour'] = ((X['TransactionDT'] / 3600) % 24).astype(int)\n",
    "    X['Transaction_weekday'] = ((X['TransactionDT'] / (3600*24)) % 7).astype(int)\n",
    "    X['is_weekend'] = (X['Transaction_weekday'] >= 5).astype(int)\n",
    "    X['is_nighttime'] = ((X['Transaction_hour'] >= 0) & (X['Transaction_hour'] <= 5)).astype(int)\n",
    "    return X\n",
    "\n",
    "def drop_unused_columns(X):\n",
    "    drop_cols = ['TransactionID', 'id_34']\n",
    "    X = X.drop(columns=[col for col in drop_cols if col in X.columns], errors='ignore')\n",
    "\n",
    "    extra_test_cols = ['id_07', 'id_08', 'id_18', 'id_21', 'id_22', 'id_23', 'id_24', 'id_25', 'id_26', 'id_27']\n",
    "    X = X.drop(columns=[col for col in extra_test_cols if col in X.columns], errors='ignore')\n",
    "\n",
    "    return X\n",
    "\n",
    "def log_transform_transaction_amt(X):\n",
    "    if 'TransactionAmt' in X.columns:\n",
    "        X['TransactionAmt_log'] = np.log1p(X['TransactionAmt'])\n",
    "    return X\n",
    "\n",
    "def run_feature_engineering(X_train, X_val, X_test):\n",
    "    print(\"🚧 Starting feature engineering pipeline...\\n\")\n",
    "\n",
    "    X_train, X_val, X_test = encode_categorical_columns(X_train, X_val, X_test)\n",
    "    print(\"✅ Encoded categorical columns\")\n",
    "\n",
    "    X_train, X_val, X_test = group_rare_categories(\n",
    "        X_train, X_val, X_test,\n",
    "        features=['P_emaildomain', 'R_emaildomain', 'id_30', 'id_31', 'id_33', 'card2', 'card5']\n",
    "    )\n",
    "    print(\"✅ Grouped rare categories\")\n",
    "\n",
    "    X_train, X_val, X_test = create_transaction_amount_ratios(X_train, X_val, X_test, ['card1', 'card4'])\n",
    "    print(\"✅ Created transaction amount ratios\")\n",
    "\n",
    "    # Apply the rest of the transformations individually\n",
    "    for name, X in zip(['Train', 'Validation', 'Test'], [X_train, X_val, X_test]):\n",
    "        X = fill_missing_values(X, X_train)\n",
    "        X = create_time_features(X)\n",
    "        X = drop_unused_columns(X)\n",
    "        X = log_transform_transaction_amt(X)\n",
    "        print(f\"✅ Completed processing {name} set\")\n",
    "        if name == 'Train':\n",
    "            X_train = X\n",
    "        elif name == 'Validation':\n",
    "            X_val = X\n",
    "        else:\n",
    "            X_test = X\n",
    "\n",
    "    print(\"\\n🎯 Final Shapes:\")\n",
    "    print(f\"📐 X_train shape: {X_train.shape}\")\n",
    "    print(f\"📐 X_val shape:   {X_val.shape}\")\n",
    "    print(f\"📐 X_test shape:  {X_test.shape}\")\n",
    "\n",
    "    return X_train, X_val, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa76d7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚧 Starting feature engineering pipeline...\n",
      "\n",
      "✅ Encoded categorical columns\n",
      "✅ Grouped rare categories\n",
      "✅ Created transaction amount ratios\n",
      "✅ Completed processing Train set\n",
      "✅ Completed processing Validation set\n",
      "✅ Completed processing Test set\n",
      "\n",
      "🎯 Final Shapes:\n",
      "📐 X_train shape: (377945, 431)\n",
      "📐 X_val shape:   (94487, 431)\n",
      "📐 X_test shape:  (118108, 431)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, X_test = run_feature_engineering(X_train, X_val, X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
